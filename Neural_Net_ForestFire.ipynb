{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. Neural Network \n",
    "* PREDICT THE BURNED AREA OF FOREST FIRES WITH NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.9.1-cp38-cp38-win_amd64.whl (444.1 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.4-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Using cached tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (20.9)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.46.3-cp38-cp38-win_amd64.whl (3.5 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.26.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Installing collected packages: importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.46.3 importlib-metadata-4.11.4 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.7 opt-einsum-3.3.0 protobuf-3.19.4 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy \n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "Forestfire = pd.read_csv('forestfires.csv')\n",
    "Forestfire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month             object\n",
       "day               object\n",
       "FFMC             float64\n",
       "DMC              float64\n",
       "DC               float64\n",
       "ISI              float64\n",
       "temp             float64\n",
       "RH                 int64\n",
       "wind             float64\n",
       "rain             float64\n",
       "area             float64\n",
       "dayfri             int64\n",
       "daymon             int64\n",
       "daysat             int64\n",
       "daysun             int64\n",
       "daythu             int64\n",
       "daytue             int64\n",
       "daywed             int64\n",
       "monthapr           int64\n",
       "monthaug           int64\n",
       "monthdec           int64\n",
       "monthfeb           int64\n",
       "monthjan           int64\n",
       "monthjul           int64\n",
       "monthjun           int64\n",
       "monthmar           int64\n",
       "monthmay           int64\n",
       "monthnov           int64\n",
       "monthoct           int64\n",
       "monthsep           int64\n",
       "size_category     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Forestfire.drop(['month','day'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  size_category  \n",
       "0           0         0          small  \n",
       "1           1         0          small  \n",
       "2           1         0          small  \n",
       "3           0         0          small  \n",
       "4           0         0          small  \n",
       "..        ...       ...            ...  \n",
       "512         0         0          large  \n",
       "513         0         0          large  \n",
       "514         0         0          large  \n",
       "515         0         0          small  \n",
       "516         0         0          small  \n",
       "\n",
       "[517 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "Forestfire['size_category'] = le.fit_transform(Forestfire['size_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FFMC   DMC     DC  ISI  temp  RH  wind  rain  area  dayfri  ...  monthfeb  \\\n",
       "0  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0       1  ...         0   \n",
       "1  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0       0  ...         0   \n",
       "2  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0       0  ...         0   \n",
       "3  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0       1  ...         0   \n",
       "4  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0       0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0              1  \n",
       "1         0              1  \n",
       "2         0              1  \n",
       "3         0              1  \n",
       "4         0              1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Forestfire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Forestfire.drop('size_category',axis=1)\n",
    "y = Forestfire['size_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FFMC    DMC     DC   ISI  temp  RH  wind  rain   area  dayfri  ...  \\\n",
       "0    86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00       1  ...   \n",
       "1    90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00       0  ...   \n",
       "2    90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00       0  ...   \n",
       "3    91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00       1  ...   \n",
       "4    89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00       0  ...   \n",
       "..    ...    ...    ...   ...   ...  ..   ...   ...    ...     ...  ...   \n",
       "512  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44       0  ...   \n",
       "513  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29       0  ...   \n",
       "514  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16       0  ...   \n",
       "515  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00       0  ...   \n",
       "516  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00       0  ...   \n",
       "\n",
       "     monthdec  monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  \\\n",
       "0           0         0         0         0         0         1         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         0         1         0   \n",
       "4           0         0         0         0         0         1         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         0   \n",
       "\n",
       "     monthnov  monthoct  monthsep  \n",
       "0           0         0         0  \n",
       "1           0         1         0  \n",
       "2           0         1         0  \n",
       "3           0         0         0  \n",
       "4           0         0         0  \n",
       "..        ...       ...       ...  \n",
       "512         0         0         0  \n",
       "513         0         0         0  \n",
       "514         0         0         0  \n",
       "515         0         0         0  \n",
       "516         1         0         0  \n",
       "\n",
       "[517 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "512    0\n",
       "513    0\n",
       "514    0\n",
       "515    1\n",
       "516    1\n",
       "Name: size_category, Length: 517, dtype: int32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X)\n",
    "x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((413, 28), (104, 28), (413,), (104,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x_scaled,y,test_size=0.20,random_state=15,stratify = y)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(28,input_dim=28,activation='relu'))\n",
    "model.add(Dense(24,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.6138 - accuracy: 0.7065 - val_loss: 0.6138 - val_accuracy: 0.7445\n",
      "Epoch 2/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7283 - val_loss: 0.5931 - val_accuracy: 0.7445\n",
      "Epoch 3/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.7283 - val_loss: 0.5923 - val_accuracy: 0.7445\n",
      "Epoch 4/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7428 - val_loss: 0.5884 - val_accuracy: 0.7737\n",
      "Epoch 5/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.7536 - val_loss: 0.5965 - val_accuracy: 0.7883\n",
      "Epoch 6/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7717 - val_loss: 0.5975 - val_accuracy: 0.8029\n",
      "Epoch 7/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7971 - val_loss: 0.6057 - val_accuracy: 0.8029\n",
      "Epoch 8/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.8007 - val_loss: 0.6099 - val_accuracy: 0.8029\n",
      "Epoch 9/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.4058 - accuracy: 0.8043 - val_loss: 0.6229 - val_accuracy: 0.7956\n",
      "Epoch 10/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8188 - val_loss: 0.6251 - val_accuracy: 0.7956\n",
      "Epoch 11/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8225 - val_loss: 0.6333 - val_accuracy: 0.8102\n",
      "Epoch 12/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8333 - val_loss: 0.6461 - val_accuracy: 0.8102\n",
      "Epoch 13/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8406 - val_loss: 0.6566 - val_accuracy: 0.7956\n",
      "Epoch 14/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8478 - val_loss: 0.6725 - val_accuracy: 0.8029\n",
      "Epoch 15/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3142 - accuracy: 0.8623 - val_loss: 0.6844 - val_accuracy: 0.7956\n",
      "Epoch 16/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.3018 - accuracy: 0.8768 - val_loss: 0.6922 - val_accuracy: 0.8029\n",
      "Epoch 17/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2890 - accuracy: 0.8587 - val_loss: 0.7055 - val_accuracy: 0.8029\n",
      "Epoch 18/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2763 - accuracy: 0.8877 - val_loss: 0.7159 - val_accuracy: 0.8175\n",
      "Epoch 19/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2650 - accuracy: 0.8949 - val_loss: 0.7330 - val_accuracy: 0.8175\n",
      "Epoch 20/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2542 - accuracy: 0.8949 - val_loss: 0.7448 - val_accuracy: 0.8175\n",
      "Epoch 21/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.9022 - val_loss: 0.7616 - val_accuracy: 0.8102\n",
      "Epoch 22/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.9094 - val_loss: 0.7783 - val_accuracy: 0.8175\n",
      "Epoch 23/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 0.9167 - val_loss: 0.7952 - val_accuracy: 0.8175\n",
      "Epoch 24/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.9203 - val_loss: 0.8080 - val_accuracy: 0.8175\n",
      "Epoch 25/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.9130 - val_loss: 0.8221 - val_accuracy: 0.8175\n",
      "Epoch 26/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9312 - val_loss: 0.8432 - val_accuracy: 0.8175\n",
      "Epoch 27/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.9348 - val_loss: 0.8534 - val_accuracy: 0.8175\n",
      "Epoch 28/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9348 - val_loss: 0.8778 - val_accuracy: 0.8102\n",
      "Epoch 29/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1695 - accuracy: 0.9348 - val_loss: 0.8938 - val_accuracy: 0.8102\n",
      "Epoch 30/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9384 - val_loss: 0.9149 - val_accuracy: 0.8102\n",
      "Epoch 31/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.9384 - val_loss: 0.9331 - val_accuracy: 0.8175\n",
      "Epoch 32/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9493 - val_loss: 0.9488 - val_accuracy: 0.8102\n",
      "Epoch 33/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9529 - val_loss: 0.9734 - val_accuracy: 0.8175\n",
      "Epoch 34/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1324 - accuracy: 0.9638 - val_loss: 0.9879 - val_accuracy: 0.8175\n",
      "Epoch 35/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1285 - accuracy: 0.9529 - val_loss: 1.0014 - val_accuracy: 0.8029\n",
      "Epoch 36/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9710 - val_loss: 1.0299 - val_accuracy: 0.8102\n",
      "Epoch 37/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9674 - val_loss: 1.0455 - val_accuracy: 0.8029\n",
      "Epoch 38/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1105 - accuracy: 0.9819 - val_loss: 1.0642 - val_accuracy: 0.8102\n",
      "Epoch 39/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9819 - val_loss: 1.0798 - val_accuracy: 0.8102\n",
      "Epoch 40/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9819 - val_loss: 1.0943 - val_accuracy: 0.8029\n",
      "Epoch 41/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9819 - val_loss: 1.1228 - val_accuracy: 0.8248\n",
      "Epoch 42/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9819 - val_loss: 1.1316 - val_accuracy: 0.8175\n",
      "Epoch 43/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0912 - accuracy: 0.9855 - val_loss: 1.1456 - val_accuracy: 0.8102\n",
      "Epoch 44/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9855 - val_loss: 1.1579 - val_accuracy: 0.8029\n",
      "Epoch 45/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9819 - val_loss: 1.1816 - val_accuracy: 0.8175\n",
      "Epoch 46/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 0.9855 - val_loss: 1.2000 - val_accuracy: 0.8175\n",
      "Epoch 47/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9819 - val_loss: 1.2126 - val_accuracy: 0.8102\n",
      "Epoch 48/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9891 - val_loss: 1.2292 - val_accuracy: 0.8102\n",
      "Epoch 49/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0707 - accuracy: 0.9891 - val_loss: 1.2401 - val_accuracy: 0.8029\n",
      "Epoch 50/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9928 - val_loss: 1.2527 - val_accuracy: 0.8029\n",
      "Epoch 51/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9891 - val_loss: 1.2734 - val_accuracy: 0.8102\n",
      "Epoch 52/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0647 - accuracy: 0.9819 - val_loss: 1.2819 - val_accuracy: 0.8102\n",
      "Epoch 53/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9928 - val_loss: 1.2998 - val_accuracy: 0.8102\n",
      "Epoch 54/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9928 - val_loss: 1.3111 - val_accuracy: 0.8102\n",
      "Epoch 55/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9891 - val_loss: 1.3227 - val_accuracy: 0.8029\n",
      "Epoch 56/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0536 - accuracy: 0.9928 - val_loss: 1.3380 - val_accuracy: 0.8102\n",
      "Epoch 57/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9891 - val_loss: 1.3531 - val_accuracy: 0.8175\n",
      "Epoch 58/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9891 - val_loss: 1.3712 - val_accuracy: 0.8175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9964 - val_loss: 1.3730 - val_accuracy: 0.8102\n",
      "Epoch 60/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9964 - val_loss: 1.4035 - val_accuracy: 0.8248\n",
      "Epoch 61/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9891 - val_loss: 1.4062 - val_accuracy: 0.8102\n",
      "Epoch 62/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9891 - val_loss: 1.4164 - val_accuracy: 0.8248\n",
      "Epoch 63/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9964 - val_loss: 1.4353 - val_accuracy: 0.8102\n",
      "Epoch 64/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9964 - val_loss: 1.4454 - val_accuracy: 0.8175\n",
      "Epoch 65/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9964 - val_loss: 1.4531 - val_accuracy: 0.8102\n",
      "Epoch 66/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9964 - val_loss: 1.4764 - val_accuracy: 0.8175\n",
      "Epoch 67/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9928 - val_loss: 1.4836 - val_accuracy: 0.8248\n",
      "Epoch 68/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9964 - val_loss: 1.4951 - val_accuracy: 0.8175\n",
      "Epoch 69/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0342 - accuracy: 0.9964 - val_loss: 1.5087 - val_accuracy: 0.8175\n",
      "Epoch 70/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9964 - val_loss: 1.5157 - val_accuracy: 0.8175\n",
      "Epoch 71/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9964 - val_loss: 1.5291 - val_accuracy: 0.8248\n",
      "Epoch 72/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9964 - val_loss: 1.5492 - val_accuracy: 0.8248\n",
      "Epoch 73/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9964 - val_loss: 1.5575 - val_accuracy: 0.8175\n",
      "Epoch 74/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9964 - val_loss: 1.5615 - val_accuracy: 0.8175\n",
      "Epoch 75/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9964 - val_loss: 1.5795 - val_accuracy: 0.8175\n",
      "Epoch 76/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9964 - val_loss: 1.5857 - val_accuracy: 0.8029\n",
      "Epoch 77/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9964 - val_loss: 1.6082 - val_accuracy: 0.8248\n",
      "Epoch 78/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9964 - val_loss: 1.6185 - val_accuracy: 0.8321\n",
      "Epoch 79/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9964 - val_loss: 1.6249 - val_accuracy: 0.8175\n",
      "Epoch 80/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.6341 - val_accuracy: 0.8175\n",
      "Epoch 81/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9964 - val_loss: 1.6501 - val_accuracy: 0.8175\n",
      "Epoch 82/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.6626 - val_accuracy: 0.8175\n",
      "Epoch 83/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.6689 - val_accuracy: 0.8175\n",
      "Epoch 84/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.6777 - val_accuracy: 0.8175\n",
      "Epoch 85/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.6989 - val_accuracy: 0.8102\n",
      "Epoch 86/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 0.9964 - val_loss: 1.7066 - val_accuracy: 0.8175\n",
      "Epoch 87/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0191 - accuracy: 0.9964 - val_loss: 1.7170 - val_accuracy: 0.8029\n",
      "Epoch 88/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 1.7337 - val_accuracy: 0.8175\n",
      "Epoch 89/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.7372 - val_accuracy: 0.8102\n",
      "Epoch 90/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.7532 - val_accuracy: 0.8175\n",
      "Epoch 91/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.7543 - val_accuracy: 0.8102\n",
      "Epoch 92/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.9964 - val_loss: 1.7774 - val_accuracy: 0.8102\n",
      "Epoch 93/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.7866 - val_accuracy: 0.8175\n",
      "Epoch 94/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.7924 - val_accuracy: 0.8175\n",
      "Epoch 95/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.8077 - val_accuracy: 0.8175\n",
      "Epoch 96/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.8215 - val_accuracy: 0.8175\n",
      "Epoch 97/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.8298 - val_accuracy: 0.8175\n",
      "Epoch 98/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.8334 - val_accuracy: 0.8102\n",
      "Epoch 99/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.8507 - val_accuracy: 0.8029\n",
      "Epoch 100/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.8673 - val_accuracy: 0.8175\n",
      "Epoch 101/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.8732 - val_accuracy: 0.8102\n",
      "Epoch 102/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.8742 - val_accuracy: 0.8102\n",
      "Epoch 103/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.8793 - val_accuracy: 0.8175\n",
      "Epoch 104/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.8937 - val_accuracy: 0.8175\n",
      "Epoch 105/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.9047 - val_accuracy: 0.8102\n",
      "Epoch 106/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.9201 - val_accuracy: 0.8175\n",
      "Epoch 107/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.9241 - val_accuracy: 0.8102\n",
      "Epoch 108/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.9504 - val_accuracy: 0.8248\n",
      "Epoch 109/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.9501 - val_accuracy: 0.8248\n",
      "Epoch 110/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.9603 - val_accuracy: 0.8175\n",
      "Epoch 111/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.9683 - val_accuracy: 0.8175\n",
      "Epoch 112/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.9809 - val_accuracy: 0.8175\n",
      "Epoch 113/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.9864 - val_accuracy: 0.8175\n",
      "Epoch 114/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.9914 - val_accuracy: 0.8175\n",
      "Epoch 115/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.9994 - val_accuracy: 0.8175\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.0132 - val_accuracy: 0.8175\n",
      "Epoch 117/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.0195 - val_accuracy: 0.8175\n",
      "Epoch 118/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.0319 - val_accuracy: 0.8248\n",
      "Epoch 119/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.0439 - val_accuracy: 0.8175\n",
      "Epoch 120/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.0527 - val_accuracy: 0.8248\n",
      "Epoch 121/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.0542 - val_accuracy: 0.8175\n",
      "Epoch 122/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.0709 - val_accuracy: 0.8175\n",
      "Epoch 123/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.0818 - val_accuracy: 0.8248\n",
      "Epoch 124/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.0882 - val_accuracy: 0.8248\n",
      "Epoch 125/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.0820 - val_accuracy: 0.8248\n",
      "Epoch 126/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.0949 - val_accuracy: 0.8175\n",
      "Epoch 127/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1103 - val_accuracy: 0.8175\n",
      "Epoch 128/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1167 - val_accuracy: 0.8248\n",
      "Epoch 129/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1294 - val_accuracy: 0.8175\n",
      "Epoch 130/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.1339 - val_accuracy: 0.8321\n",
      "Epoch 131/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.1452 - val_accuracy: 0.8248\n",
      "Epoch 132/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1519 - val_accuracy: 0.8321\n",
      "Epoch 133/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.1714 - val_accuracy: 0.8321\n",
      "Epoch 134/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1756 - val_accuracy: 0.8248\n",
      "Epoch 135/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.1761 - val_accuracy: 0.8321\n",
      "Epoch 136/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.1903 - val_accuracy: 0.8321\n",
      "Epoch 137/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.1939 - val_accuracy: 0.8321\n",
      "Epoch 138/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.2023 - val_accuracy: 0.8321\n",
      "Epoch 139/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.2089 - val_accuracy: 0.8321\n",
      "Epoch 140/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.2173 - val_accuracy: 0.8321\n",
      "Epoch 141/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2246 - val_accuracy: 0.8321\n",
      "Epoch 142/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.2315 - val_accuracy: 0.8321\n",
      "Epoch 143/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.2461 - val_accuracy: 0.8321\n",
      "Epoch 144/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.2486 - val_accuracy: 0.8321\n",
      "Epoch 145/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.2681 - val_accuracy: 0.8321\n",
      "Epoch 146/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.2698 - val_accuracy: 0.8321\n",
      "Epoch 147/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.2735 - val_accuracy: 0.8321\n",
      "Epoch 148/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.2802 - val_accuracy: 0.8321\n",
      "Epoch 149/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.2865 - val_accuracy: 0.8248\n",
      "Epoch 150/150\n",
      "28/28 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.2944 - val_accuracy: 0.8248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14941992820>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,validation_split=0.33,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 500us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "rounded = [round(x[0]) for x in y_pred_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train1 = pd.DataFrame(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>413 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "..  ..\n",
       "408  0\n",
       "409  1\n",
       "410  1\n",
       "411  1\n",
       "412  1\n",
       "\n",
       "[413 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 667us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "rounded1    = [round(x[0]) for x in y_pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "..  ..\n",
       "99   0\n",
       "100  1\n",
       "101  1\n",
       "102  1\n",
       "103  0\n",
       "\n",
       "[104 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test1 = pd.DataFrame(rounded1)\n",
    "y_pred_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.018295785412192345, 1.0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Train = model.evaluate(X_train,y_pred_train1,verbose=0)\n",
    "Accuracy_Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03664736449718475, 1.0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy_Test = model.evaluate(X_test,y_pred_test1,verbose=0)\n",
    "Accuracy_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 0.9855 - val_loss: 0.0403 - val_accuracy: 1.0000\n",
      "Epoch 2/150\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 3/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9714\n",
      "Epoch 4/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9714\n",
      "Epoch 5/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9714\n",
      "Epoch 6/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9714\n",
      "Epoch 7/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9714\n",
      "Epoch 8/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9714\n",
      "Epoch 9/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9714\n",
      "Epoch 10/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9714\n",
      "Epoch 11/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.2019e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9714\n",
      "Epoch 12/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.4928e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9714\n",
      "Epoch 13/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 8.0015e-04 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9714\n",
      "Epoch 14/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.5653e-04 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9714\n",
      "Epoch 15/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.1628e-04 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9714\n",
      "Epoch 16/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.7627e-04 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9714\n",
      "Epoch 17/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.5271e-04 - accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9714\n",
      "Epoch 18/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.2399e-04 - accuracy: 1.0000 - val_loss: 0.0920 - val_accuracy: 0.9714\n",
      "Epoch 19/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.9932e-04 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 0.9714\n",
      "Epoch 20/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.7548e-04 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9714\n",
      "Epoch 21/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.5651e-04 - accuracy: 1.0000 - val_loss: 0.0943 - val_accuracy: 0.9714\n",
      "Epoch 22/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.3696e-04 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9714\n",
      "Epoch 23/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.2201e-04 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9714\n",
      "Epoch 24/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.0424e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9714\n",
      "Epoch 25/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.9072e-04 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9714\n",
      "Epoch 26/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.7804e-04 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9714\n",
      "Epoch 27/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.6276e-04 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9714\n",
      "Epoch 28/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.5206e-04 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9714\n",
      "Epoch 29/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.4058e-04 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9714\n",
      "Epoch 30/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.2951e-04 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9714\n",
      "Epoch 31/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.2001e-04 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9714\n",
      "Epoch 32/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.1123e-04 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9714\n",
      "Epoch 33/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.0119e-04 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9714\n",
      "Epoch 34/150\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.9186e-04 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9714\n",
      "Epoch 35/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8432e-04 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9714\n",
      "Epoch 36/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.7614e-04 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9714\n",
      "Epoch 37/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6793e-04 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9714\n",
      "Epoch 38/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6062e-04 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9714\n",
      "Epoch 39/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5419e-04 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9714\n",
      "Epoch 40/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.4726e-04 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9714\n",
      "Epoch 41/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.4122e-04 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9714\n",
      "Epoch 42/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.3457e-04 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9714\n",
      "Epoch 43/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.2848e-04 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9714\n",
      "Epoch 44/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.2343e-04 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9714\n",
      "Epoch 45/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.1803e-04 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9714\n",
      "Epoch 46/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.1253e-04 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9714\n",
      "Epoch 47/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.0636e-04 - accuracy: 1.0000 - val_loss: 0.1129 - val_accuracy: 0.9714\n",
      "Epoch 48/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.0236e-04 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9714\n",
      "Epoch 49/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.9690e-04 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9714\n",
      "Epoch 50/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.9246e-04 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9714\n",
      "Epoch 51/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8886e-04 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9714\n",
      "Epoch 52/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8357e-04 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9714\n",
      "Epoch 53/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7937e-04 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9714\n",
      "Epoch 54/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7559e-04 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9714\n",
      "Epoch 55/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7092e-04 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9714\n",
      "Epoch 56/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.6738e-04 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9714\n",
      "Epoch 57/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.6366e-04 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9714\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5999e-04 - accuracy: 1.0000 - val_loss: 0.1188 - val_accuracy: 0.9714\n",
      "Epoch 59/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5614e-04 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9714\n",
      "Epoch 60/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5277e-04 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9714\n",
      "Epoch 61/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4912e-04 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9714\n",
      "Epoch 62/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4597e-04 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9714\n",
      "Epoch 63/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4314e-04 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9714\n",
      "Epoch 64/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.3928e-04 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9714\n",
      "Epoch 65/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.3695e-04 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9714\n",
      "Epoch 66/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.3335e-04 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9714\n",
      "Epoch 67/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.3057e-04 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9714\n",
      "Epoch 68/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2785e-04 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9714\n",
      "Epoch 69/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2481e-04 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9714\n",
      "Epoch 70/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2201e-04 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9714\n",
      "Epoch 71/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1955e-04 - accuracy: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9714\n",
      "Epoch 72/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1695e-04 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9714\n",
      "Epoch 73/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1458e-04 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9714\n",
      "Epoch 74/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1191e-04 - accuracy: 1.0000 - val_loss: 0.1257 - val_accuracy: 0.9714\n",
      "Epoch 75/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0965e-04 - accuracy: 1.0000 - val_loss: 0.1261 - val_accuracy: 0.9714\n",
      "Epoch 76/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0740e-04 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9714\n",
      "Epoch 77/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0490e-04 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9714\n",
      "Epoch 78/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0270e-04 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9714\n",
      "Epoch 79/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0041e-04 - accuracy: 1.0000 - val_loss: 0.1277 - val_accuracy: 0.9714\n",
      "Epoch 80/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9810e-04 - accuracy: 1.0000 - val_loss: 0.1282 - val_accuracy: 0.9714\n",
      "Epoch 81/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9605e-04 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9714\n",
      "Epoch 82/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9394e-04 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9714\n",
      "Epoch 83/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9184e-04 - accuracy: 1.0000 - val_loss: 0.1292 - val_accuracy: 0.9714\n",
      "Epoch 84/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9002e-04 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9714\n",
      "Epoch 85/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8793e-04 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9714\n",
      "Epoch 86/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8605e-04 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9714\n",
      "Epoch 87/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8436e-04 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9714\n",
      "Epoch 88/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8253e-04 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9714\n",
      "Epoch 89/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8053e-04 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 0.9714\n",
      "Epoch 90/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7867e-04 - accuracy: 1.0000 - val_loss: 0.1317 - val_accuracy: 0.9714\n",
      "Epoch 91/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7706e-04 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9714\n",
      "Epoch 92/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7510e-04 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9714\n",
      "Epoch 93/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7345e-04 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9714\n",
      "Epoch 94/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7209e-04 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9714\n",
      "Epoch 95/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7057e-04 - accuracy: 1.0000 - val_loss: 0.1335 - val_accuracy: 0.9714\n",
      "Epoch 96/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.6848e-04 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9714\n",
      "Epoch 97/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.6706e-04 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9714\n",
      "Epoch 98/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.6547e-04 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9714\n",
      "Epoch 99/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.6387e-04 - accuracy: 1.0000 - val_loss: 0.1347 - val_accuracy: 0.9714\n",
      "Epoch 100/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.6232e-04 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9714\n",
      "Epoch 101/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.6104e-04 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9714\n",
      "Epoch 102/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5947e-04 - accuracy: 1.0000 - val_loss: 0.1358 - val_accuracy: 0.9714\n",
      "Epoch 103/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5812e-04 - accuracy: 1.0000 - val_loss: 0.1361 - val_accuracy: 0.9714\n",
      "Epoch 104/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5683e-04 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9714\n",
      "Epoch 105/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5510e-04 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9714\n",
      "Epoch 106/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5407e-04 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9714\n",
      "Epoch 107/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5262e-04 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9714\n",
      "Epoch 108/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5120e-04 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9714\n",
      "Epoch 109/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4994e-04 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9714\n",
      "Epoch 110/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4882e-04 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9714\n",
      "Epoch 111/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4755e-04 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9714\n",
      "Epoch 112/150\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.4618e-04 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9714\n",
      "Epoch 113/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4503e-04 - accuracy: 1.0000 - val_loss: 0.1391 - val_accuracy: 0.9714\n",
      "Epoch 114/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4376e-04 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4250e-04 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9714\n",
      "Epoch 116/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4151e-04 - accuracy: 1.0000 - val_loss: 0.1400 - val_accuracy: 0.9714\n",
      "Epoch 117/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4029e-04 - accuracy: 1.0000 - val_loss: 0.1402 - val_accuracy: 0.9714\n",
      "Epoch 118/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3904e-04 - accuracy: 1.0000 - val_loss: 0.1405 - val_accuracy: 0.9714\n",
      "Epoch 119/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3801e-04 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9714\n",
      "Epoch 120/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3690e-04 - accuracy: 1.0000 - val_loss: 0.1411 - val_accuracy: 0.9714\n",
      "Epoch 121/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3577e-04 - accuracy: 1.0000 - val_loss: 0.1414 - val_accuracy: 0.9714\n",
      "Epoch 122/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3473e-04 - accuracy: 1.0000 - val_loss: 0.1416 - val_accuracy: 0.9714\n",
      "Epoch 123/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3361e-04 - accuracy: 1.0000 - val_loss: 0.1419 - val_accuracy: 0.9714\n",
      "Epoch 124/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3265e-04 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9714\n",
      "Epoch 125/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3160e-04 - accuracy: 1.0000 - val_loss: 0.1425 - val_accuracy: 0.9714\n",
      "Epoch 126/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.3057e-04 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 0.9714\n",
      "Epoch 127/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2959e-04 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9714\n",
      "Epoch 128/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2854e-04 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9714\n",
      "Epoch 129/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2761e-04 - accuracy: 1.0000 - val_loss: 0.1436 - val_accuracy: 0.9714\n",
      "Epoch 130/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2658e-04 - accuracy: 1.0000 - val_loss: 0.1438 - val_accuracy: 0.9714\n",
      "Epoch 131/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2574e-04 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9714\n",
      "Epoch 132/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2483e-04 - accuracy: 1.0000 - val_loss: 0.1443 - val_accuracy: 0.9714\n",
      "Epoch 133/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2381e-04 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 0.9714\n",
      "Epoch 134/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2283e-04 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 0.9714\n",
      "Epoch 135/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2211e-04 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9714\n",
      "Epoch 136/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2107e-04 - accuracy: 1.0000 - val_loss: 0.1453 - val_accuracy: 0.9714\n",
      "Epoch 137/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2012e-04 - accuracy: 1.0000 - val_loss: 0.1456 - val_accuracy: 0.9714\n",
      "Epoch 138/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1933e-04 - accuracy: 1.0000 - val_loss: 0.1458 - val_accuracy: 0.9714\n",
      "Epoch 139/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1849e-04 - accuracy: 1.0000 - val_loss: 0.1460 - val_accuracy: 0.9714\n",
      "Epoch 140/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1755e-04 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9714\n",
      "Epoch 141/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1684e-04 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 0.9714\n",
      "Epoch 142/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1594e-04 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9714\n",
      "Epoch 143/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1506e-04 - accuracy: 1.0000 - val_loss: 0.1470 - val_accuracy: 0.9714\n",
      "Epoch 144/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1438e-04 - accuracy: 1.0000 - val_loss: 0.1472 - val_accuracy: 0.9714\n",
      "Epoch 145/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1350e-04 - accuracy: 1.0000 - val_loss: 0.1475 - val_accuracy: 0.9714\n",
      "Epoch 146/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1279e-04 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9714\n",
      "Epoch 147/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1201e-04 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9714\n",
      "Epoch 148/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1115e-04 - accuracy: 1.0000 - val_loss: 0.1481 - val_accuracy: 0.9714\n",
      "Epoch 149/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.1046e-04 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9714\n",
      "Epoch 150/150\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.0964e-04 - accuracy: 1.0000 - val_loss: 0.1486 - val_accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "History = model.fit(X_test,y_pred_test1,validation_split=0.33,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(History.history['accuracy'])\n",
    "plt.plot(History.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(History.history['loss'])\n",
    "plt.plot(History.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning of Hyperparameters : Batch Size and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimizers\n",
      "  Downloading Optimizers-v2.1.tar.gz (1.6 kB)\n",
      "Requirement already satisfied: requests>=2.24.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from optimizers) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->optimizers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->optimizers) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->optimizers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.24.0->optimizers) (2020.12.5)\n",
      "Building wheels for collected packages: optimizers\n",
      "  Building wheel for optimizers (setup.py): started\n",
      "  Building wheel for optimizers (setup.py): finished with status 'done'\n",
      "  Created wheel for optimizers: filename=Optimizers-2.1-py3-none-any.whl size=2285 sha256=5957d7ac438304bc515b38dd3c9b23bfc2dc9cf6bb62e1bf8b016438b8d9b7b2\n",
      "  Stored in directory: c:\\users\\farza\\appdata\\local\\pip\\cache\\wheels\\1d\\e3\\e3\\f0a9b8fd8a9271274d03d4c15e4fed24a70b1d1b0f571bec66\n",
      "Successfully built optimizers\n",
      "Installing collected packages: optimizers\n",
      "Successfully installed optimizers-2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(30, input_dim=28, activation='relu'))\n",
    "    model1.add(Dense(28, activation='relu'))\n",
    "    model1.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "   \n",
    "    model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END ..................batch_size=10, epochs=10; total time=   0.5s\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/9] END ..................batch_size=10, epochs=10; total time=   0.5s\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/9] END ..................batch_size=10, epochs=10; total time=   0.5s\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/9] END ..................batch_size=10, epochs=10; total time=   0.5s\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/9] END ..................batch_size=10, epochs=10; total time=   0.6s\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/5; 2/9] END ..................batch_size=10, epochs=50; total time=   1.3s\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/5; 2/9] END ..................batch_size=10, epochs=50; total time=   1.3s\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/5; 2/9] END ..................batch_size=10, epochs=50; total time=   1.3s\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 4/5; 2/9] END ..................batch_size=10, epochs=50; total time=   1.3s\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 5/5; 2/9] END ..................batch_size=10, epochs=50; total time=   1.3s\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/5; 3/9] END .................batch_size=10, epochs=100; total time=   2.4s\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/5; 3/9] END .................batch_size=10, epochs=100; total time=   2.4s\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/5; 3/9] END .................batch_size=10, epochs=100; total time=   2.4s\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 4/5; 3/9] END .................batch_size=10, epochs=100; total time=   2.4s\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 5/5; 3/9] END .................batch_size=10, epochs=100; total time=   2.4s\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/5; 4/9] END ..................batch_size=20, epochs=10; total time=   0.6s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/5; 4/9] END ..................batch_size=20, epochs=10; total time=   0.4s\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/5; 4/9] END ..................batch_size=20, epochs=10; total time=   0.4s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 4/5; 4/9] END ..................batch_size=20, epochs=10; total time=   0.4s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 5/5; 4/9] END ..................batch_size=20, epochs=10; total time=   0.4s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/5; 5/9] END ..................batch_size=20, epochs=50; total time=   0.8s\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/5; 5/9] END ..................batch_size=20, epochs=50; total time=   0.8s\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/5; 5/9] END ..................batch_size=20, epochs=50; total time=   0.8s\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 4/5; 5/9] END ..................batch_size=20, epochs=50; total time=   0.8s\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 5/5; 5/9] END ..................batch_size=20, epochs=50; total time=   0.8s\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/5; 6/9] END .................batch_size=20, epochs=100; total time=   1.5s\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/5; 6/9] END .................batch_size=20, epochs=100; total time=   1.4s\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/5; 6/9] END .................batch_size=20, epochs=100; total time=   1.4s\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 4/5; 6/9] END .................batch_size=20, epochs=100; total time=   1.3s\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 5/5; 6/9] END .................batch_size=20, epochs=100; total time=   1.3s\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/5; 7/9] END ..................batch_size=40, epochs=10; total time=   0.3s\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/5; 7/9] END ..................batch_size=40, epochs=10; total time=   0.3s\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/5; 7/9] END ..................batch_size=40, epochs=10; total time=   0.3s\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x000001494BC8D310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 4/5; 7/9] END ..................batch_size=40, epochs=10; total time=   0.3s\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001494653F670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 5/5; 7/9] END ..................batch_size=40, epochs=10; total time=   0.3s\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/5; 8/9] END ..................batch_size=40, epochs=50; total time=   0.6s\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/5; 8/9] END ..................batch_size=40, epochs=50; total time=   0.8s\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/5; 8/9] END ..................batch_size=40, epochs=50; total time=   0.6s\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 4/5; 8/9] END ..................batch_size=40, epochs=50; total time=   0.6s\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 5/5; 8/9] END ..................batch_size=40, epochs=50; total time=   0.6s\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/5; 9/9] END .................batch_size=40, epochs=100; total time=   0.8s\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 2/5; 9/9] END .................batch_size=40, epochs=100; total time=   0.9s\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/9] END .................batch_size=40, epochs=100; total time=   0.9s\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 4/5; 9/9] END .................batch_size=40, epochs=100; total time=   0.9s\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 5/5; 9/9] END .................batch_size=40, epochs=100; total time=   0.9s\n"
     ]
    }
   ],
   "source": [
    "model2 = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "grid = GridSearchCV(estimator = model2,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.8876960396766662, using {'batch_size': 10, 'epochs': 100}\n",
      "0.7346527338027954,0.09907131969869527 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.8625653505325317,0.062098651619333936 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.8876960396766662,0.04768251029343508 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.7461165070533753,0.14678828387197831 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.8450896143913269,0.053949119140279875 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.8528379440307617,0.07064903353595246 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.7305638432502747,0.15966032524782298 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.7655900001525879,0.0957791231665867 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.8296303272247314,0.06398875969487192 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From summary we can say best result ,when batch-size = 10 and epochs=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning of Hyperparameter :Number of neurons in activation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model1(neuron1,neuron2):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(neuron1,input_dim = 28,activation = 'relu'))\n",
    "    model3.add(Dense(neuron2,activation = 'relu'))\n",
    "    model3.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    model3.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    return model3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=24, neuron2=20......................................\n",
      "[CV 1/5; 1/9] END ....................neuron1=24, neuron2=20; total time=   0.5s\n",
      "[CV 2/5; 1/9] START neuron1=24, neuron2=20......................................\n",
      "[CV 2/5; 1/9] END ....................neuron1=24, neuron2=20; total time=   0.3s\n",
      "[CV 3/5; 1/9] START neuron1=24, neuron2=20......................................\n",
      "[CV 3/5; 1/9] END ....................neuron1=24, neuron2=20; total time=   0.3s\n",
      "[CV 4/5; 1/9] START neuron1=24, neuron2=20......................................\n",
      "[CV 4/5; 1/9] END ....................neuron1=24, neuron2=20; total time=   0.3s\n",
      "[CV 5/5; 1/9] START neuron1=24, neuron2=20......................................\n",
      "[CV 5/5; 1/9] END ....................neuron1=24, neuron2=20; total time=   0.3s\n",
      "[CV 1/5; 2/9] START neuron1=24, neuron2=24......................................\n",
      "[CV 1/5; 2/9] END ....................neuron1=24, neuron2=24; total time=   0.3s\n",
      "[CV 2/5; 2/9] START neuron1=24, neuron2=24......................................\n",
      "[CV 2/5; 2/9] END ....................neuron1=24, neuron2=24; total time=   0.3s\n",
      "[CV 3/5; 2/9] START neuron1=24, neuron2=24......................................\n",
      "[CV 3/5; 2/9] END ....................neuron1=24, neuron2=24; total time=   0.3s\n",
      "[CV 4/5; 2/9] START neuron1=24, neuron2=24......................................\n",
      "[CV 4/5; 2/9] END ....................neuron1=24, neuron2=24; total time=   0.3s\n",
      "[CV 5/5; 2/9] START neuron1=24, neuron2=24......................................\n",
      "[CV 5/5; 2/9] END ....................neuron1=24, neuron2=24; total time=   0.3s\n",
      "[CV 1/5; 3/9] START neuron1=24, neuron2=28......................................\n",
      "[CV 1/5; 3/9] END ....................neuron1=24, neuron2=28; total time=   0.3s\n",
      "[CV 2/5; 3/9] START neuron1=24, neuron2=28......................................\n",
      "[CV 2/5; 3/9] END ....................neuron1=24, neuron2=28; total time=   0.3s\n",
      "[CV 3/5; 3/9] START neuron1=24, neuron2=28......................................\n",
      "[CV 3/5; 3/9] END ....................neuron1=24, neuron2=28; total time=   0.6s\n",
      "[CV 4/5; 3/9] START neuron1=24, neuron2=28......................................\n",
      "[CV 4/5; 3/9] END ....................neuron1=24, neuron2=28; total time=   0.3s\n",
      "[CV 5/5; 3/9] START neuron1=24, neuron2=28......................................\n",
      "[CV 5/5; 3/9] END ....................neuron1=24, neuron2=28; total time=   0.3s\n",
      "[CV 1/5; 4/9] START neuron1=28, neuron2=20......................................\n",
      "[CV 1/5; 4/9] END ....................neuron1=28, neuron2=20; total time=   0.3s\n",
      "[CV 2/5; 4/9] START neuron1=28, neuron2=20......................................\n",
      "[CV 2/5; 4/9] END ....................neuron1=28, neuron2=20; total time=   0.3s\n",
      "[CV 3/5; 4/9] START neuron1=28, neuron2=20......................................\n",
      "[CV 3/5; 4/9] END ....................neuron1=28, neuron2=20; total time=   0.3s\n",
      "[CV 4/5; 4/9] START neuron1=28, neuron2=20......................................\n",
      "[CV 4/5; 4/9] END ....................neuron1=28, neuron2=20; total time=   0.4s\n",
      "[CV 5/5; 4/9] START neuron1=28, neuron2=20......................................\n",
      "[CV 5/5; 4/9] END ....................neuron1=28, neuron2=20; total time=   0.4s\n",
      "[CV 1/5; 5/9] START neuron1=28, neuron2=24......................................\n",
      "[CV 1/5; 5/9] END ....................neuron1=28, neuron2=24; total time=   0.3s\n",
      "[CV 2/5; 5/9] START neuron1=28, neuron2=24......................................\n",
      "[CV 2/5; 5/9] END ....................neuron1=28, neuron2=24; total time=   0.4s\n",
      "[CV 3/5; 5/9] START neuron1=28, neuron2=24......................................\n",
      "[CV 3/5; 5/9] END ....................neuron1=28, neuron2=24; total time=   0.6s\n",
      "[CV 4/5; 5/9] START neuron1=28, neuron2=24......................................\n",
      "[CV 4/5; 5/9] END ....................neuron1=28, neuron2=24; total time=   0.3s\n",
      "[CV 5/5; 5/9] START neuron1=28, neuron2=24......................................\n",
      "[CV 5/5; 5/9] END ....................neuron1=28, neuron2=24; total time=   0.3s\n",
      "[CV 1/5; 6/9] START neuron1=28, neuron2=28......................................\n",
      "[CV 1/5; 6/9] END ....................neuron1=28, neuron2=28; total time=   0.3s\n",
      "[CV 2/5; 6/9] START neuron1=28, neuron2=28......................................\n",
      "[CV 2/5; 6/9] END ....................neuron1=28, neuron2=28; total time=   0.3s\n",
      "[CV 3/5; 6/9] START neuron1=28, neuron2=28......................................\n",
      "[CV 3/5; 6/9] END ....................neuron1=28, neuron2=28; total time=   0.3s\n",
      "[CV 4/5; 6/9] START neuron1=28, neuron2=28......................................\n",
      "[CV 4/5; 6/9] END ....................neuron1=28, neuron2=28; total time=   0.3s\n",
      "[CV 5/5; 6/9] START neuron1=28, neuron2=28......................................\n",
      "[CV 5/5; 6/9] END ....................neuron1=28, neuron2=28; total time=   0.3s\n",
      "[CV 1/5; 7/9] START neuron1=35, neuron2=20......................................\n",
      "[CV 1/5; 7/9] END ....................neuron1=35, neuron2=20; total time=   0.3s\n",
      "[CV 2/5; 7/9] START neuron1=35, neuron2=20......................................\n",
      "[CV 2/5; 7/9] END ....................neuron1=35, neuron2=20; total time=   0.3s\n",
      "[CV 3/5; 7/9] START neuron1=35, neuron2=20......................................\n",
      "[CV 3/5; 7/9] END ....................neuron1=35, neuron2=20; total time=   0.3s\n",
      "[CV 4/5; 7/9] START neuron1=35, neuron2=20......................................\n",
      "[CV 4/5; 7/9] END ....................neuron1=35, neuron2=20; total time=   0.5s\n",
      "[CV 5/5; 7/9] START neuron1=35, neuron2=20......................................\n",
      "[CV 5/5; 7/9] END ....................neuron1=35, neuron2=20; total time=   0.3s\n",
      "[CV 1/5; 8/9] START neuron1=35, neuron2=24......................................\n",
      "[CV 1/5; 8/9] END ....................neuron1=35, neuron2=24; total time=   0.3s\n",
      "[CV 2/5; 8/9] START neuron1=35, neuron2=24......................................\n",
      "[CV 2/5; 8/9] END ....................neuron1=35, neuron2=24; total time=   0.3s\n",
      "[CV 3/5; 8/9] START neuron1=35, neuron2=24......................................\n",
      "[CV 3/5; 8/9] END ....................neuron1=35, neuron2=24; total time=   0.3s\n",
      "[CV 4/5; 8/9] START neuron1=35, neuron2=24......................................\n",
      "[CV 4/5; 8/9] END ....................neuron1=35, neuron2=24; total time=   0.3s\n",
      "[CV 5/5; 8/9] START neuron1=35, neuron2=24......................................\n",
      "[CV 5/5; 8/9] END ....................neuron1=35, neuron2=24; total time=   0.3s\n",
      "[CV 1/5; 9/9] START neuron1=35, neuron2=28......................................\n",
      "[CV 1/5; 9/9] END ....................neuron1=35, neuron2=28; total time=   0.3s\n",
      "[CV 2/5; 9/9] START neuron1=35, neuron2=28......................................\n",
      "[CV 2/5; 9/9] END ....................neuron1=35, neuron2=28; total time=   0.3s\n",
      "[CV 3/5; 9/9] START neuron1=35, neuron2=28......................................\n",
      "[CV 3/5; 9/9] END ....................neuron1=35, neuron2=28; total time=   0.3s\n",
      "[CV 4/5; 9/9] START neuron1=35, neuron2=28......................................\n",
      "[CV 4/5; 9/9] END ....................neuron1=35, neuron2=28; total time=   0.5s\n",
      "[CV 5/5; 9/9] START neuron1=35, neuron2=28......................................\n",
      "[CV 5/5; 9/9] END ....................neuron1=35, neuron2=28; total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "model4 = KerasClassifier(build_fn = create_model1,verbose = 0,batch_size = 40,epochs = 10)\n",
    "neuron1 = [24,28,35]\n",
    "neuron2 = [20,24,28]\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "grid2        = GridSearchCV(estimator = model4,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result2 = grid2.fit(x_scaled,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7344846963882447, using {'neuron1': 28, 'neuron2': 24}\n",
      "0.7306945562362671,0.12474564014577386 with: {'neuron1': 24, 'neuron2': 20}\n",
      "0.7094099998474122,0.12249133394478744 with: {'neuron1': 24, 'neuron2': 24}\n",
      "0.7248506307601928,0.1374873177534645 with: {'neuron1': 24, 'neuron2': 28}\n",
      "0.7132748365402222,0.12528507201800687 with: {'neuron1': 28, 'neuron2': 20}\n",
      "0.7344846963882447,0.1473974962192127 with: {'neuron1': 28, 'neuron2': 24}\n",
      "0.7286967873573303,0.14351144456028408 with: {'neuron1': 28, 'neuron2': 28}\n",
      "0.7288088202476501,0.11174212236669616 with: {'neuron1': 35, 'neuron2': 20}\n",
      "0.7267923831939698,0.13468071675427679 with: {'neuron1': 35, 'neuron2': 24}\n",
      "0.7133495092391968,0.10138080335830492 with: {'neuron1': 35, 'neuron2': 28}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result2.best_score_,grid_result2.best_params_))\n",
    "means = grid_result2.cv_results_['mean_test_score']\n",
    "stds = grid_result2.cv_results_['std_test_score']\n",
    "params = grid_result2.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  From summary best result at 1st layer 28 Neuron and 2nd layer 24 neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameter : Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2(activation_function):\n",
    "    model4 = Sequential()\n",
    "    model4.add(Dense(28,input_dim = 28,activation = activation_function))\n",
    "    model4.add(Dense(24,activation = activation_function))\n",
    "    model4.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    model4.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    return model4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START activation_function=softmax.................................\n",
      "[CV 1/5; 1/3] END ...............activation_function=softmax; total time=   0.3s\n",
      "[CV 2/5; 1/3] START activation_function=softmax.................................\n",
      "[CV 2/5; 1/3] END ...............activation_function=softmax; total time=   0.3s\n",
      "[CV 3/5; 1/3] START activation_function=softmax.................................\n",
      "[CV 3/5; 1/3] END ...............activation_function=softmax; total time=   0.3s\n",
      "[CV 4/5; 1/3] START activation_function=softmax.................................\n",
      "[CV 4/5; 1/3] END ...............activation_function=softmax; total time=   0.3s\n",
      "[CV 5/5; 1/3] START activation_function=softmax.................................\n",
      "[CV 5/5; 1/3] END ...............activation_function=softmax; total time=   0.4s\n",
      "[CV 1/5; 2/3] START activation_function=relu....................................\n",
      "[CV 1/5; 2/3] END ..................activation_function=relu; total time=   0.4s\n",
      "[CV 2/5; 2/3] START activation_function=relu....................................\n",
      "[CV 2/5; 2/3] END ..................activation_function=relu; total time=   0.3s\n",
      "[CV 3/5; 2/3] START activation_function=relu....................................\n",
      "[CV 3/5; 2/3] END ..................activation_function=relu; total time=   0.3s\n",
      "[CV 4/5; 2/3] START activation_function=relu....................................\n",
      "[CV 4/5; 2/3] END ..................activation_function=relu; total time=   0.5s\n",
      "[CV 5/5; 2/3] START activation_function=relu....................................\n",
      "[CV 5/5; 2/3] END ..................activation_function=relu; total time=   0.3s\n",
      "[CV 1/5; 3/3] START activation_function=tanh....................................\n",
      "[CV 1/5; 3/3] END ..................activation_function=tanh; total time=   0.3s\n",
      "[CV 2/5; 3/3] START activation_function=tanh....................................\n",
      "[CV 2/5; 3/3] END ..................activation_function=tanh; total time=   0.3s\n",
      "[CV 3/5; 3/3] START activation_function=tanh....................................\n",
      "[CV 3/5; 3/3] END ..................activation_function=tanh; total time=   0.3s\n",
      "[CV 4/5; 3/3] START activation_function=tanh....................................\n",
      "[CV 4/5; 3/3] END ..................activation_function=tanh; total time=   0.3s\n",
      "[CV 5/5; 3/3] START activation_function=tanh....................................\n",
      "[CV 5/5; 3/3] END ..................activation_function=tanh; total time=   0.3s\n"
     ]
    }
   ],
   "source": [
    "model5 = KerasClassifier(build_fn = create_model2,verbose = 0,batch_size = 40,epochs = 10)\n",
    "activation_function = ['softmax','relu','tanh']\n",
    "param_grids = dict(activation_function=activation_function)\n",
    "grid3        = GridSearchCV(estimator = model5,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result3 = grid3.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.7558999180793762, using {'activation_function': 'tanh'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax'}\n",
      "0.7267737030982971,0.14027757123023468 with: {'activation_function': 'relu'}\n",
      "0.7558999180793762,0.11087344966471313 with: {'activation_function': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result3.best_score_,grid_result3.best_params_))\n",
    "means = grid_result3.cv_results_['mean_test_score']\n",
    "stds = grid_result3.cv_results_['std_test_score']\n",
    "params = grid_result3.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From summary best result when Activation function is 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
